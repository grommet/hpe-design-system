# Copilot Instructions for HPE Design System Agent

Welcome! This document helps you navigate the design system agent project, understand key design decisions, and contribute effectively.

---

## Project Context

### What is this?

The HPE Design System Agent is an LLM-driven multi-agent system that audits Grommet-based React codebases against 11 design system metrics (Component Coverage, Token Compliance, Accessibility, Type Safety, etc.), recommends high-impact fixes, and generates or remediates code with human approval gates.

### Architecture

- **Orchestrator:** Master loop controller; manages state, config discovery, approval gating
- **Auditor:** Produces metric scorecards (11-point framework) using component/pattern/token knowledge base
- **Strategist:** Ranks top 3 recommendations by impact/effort ratio; classifies Consumer vs. System gaps
- **Engineer:** Remediates (fixes violations) or generates (scaffolds new features) using skills (Token Compliance, Component Usage, text→code, Figma→code, PRD→code)
- **Reporter:** Collects telemetry, honors opt-out, detects P1 system gaps

### PoC Scope (Current: Segment A Only)

**What's in scope:**

- **Framework:** React (only)
- **UI Library:** Grommet + `grommet-theme-hpe` (only)
- **Team Segment:** Segment A: mature HPEDS adoption
- **Engineer Skills:** Token Compliance fixes, Component Usage fixes, Grommet-only generation (text/Figma/PRD)
- **Metrics Remediable:** Token Compliance, Component Usage (no Accessibility/Type Safety/DX auto-fix in PoC)

**Explicitly out of scope (defer to MVP/Enhancements):**

- Non-React frameworks (Vue, Angular, Svelte)
- Non-Grommet UI libraries (Material-UI, Chakra, Bootstrap, custom)
- Monorepo support (beyond pnpm-workspace.yaml detection)
- Pattern audit scope
- CI/PR passive mode (monitoring without fixes)

### Roadmap

- **Phase 1 (PoC):** Segment A, Grommet remediation + generation, 4-6 weeks (see [PoC-IMPLEMENTATION.md](PoC-IMPLEMENTATION.md))
- **Phase 2 (MVP):** Segments A-D, all React libraries, passive CI/PR mode, 8-12 weeks
- **Phase 3 (Enhancements):** Segments E-F, Vue/Angular, pattern analytics, continuous loop

---

## First-Time Contributor Setup (5–10 minutes)

New to this project? Start here.

### 1. Explore the codebase (2 min)

```bash
cd packages/design-system-agent

# Read the README to understand the project
cat DOCUMENTATION.md | head -100

# Review the roadmap
cat ROADMAP.md | grep -A 20 "Phase 1"

# Check the PoC implementation plan
cat PoC-IMPLEMENTATION.md | grep "Workstreams" -A 50
```

### 2. Understand the architecture (3 min)

- **Read:** PoC Scope section above (PoC = Segment A, Grommet, React only)
- **Read:** Key Design Decisions #1–3 (PoC scope limits, approval gates, Orchestrator ownership)
- **Skim:** DOCUMENTATION.md "Agent Definitions" section (5 agents, their roles)
- **Key takeaway:** If you're unsure whether a feature is in-scope, assume it's not unless tied to Segment A validation

### 3. Run a test audit (optional, 3–5 min)

```bash
# Create a minimal .hpedsrc in a test Grommet repo
cat > .hpedsrc <<EOF
framework: react
team_segment: A
scope: directory
scope_target: src
post_generation_audit: false
telemetry_opt_in: true
EOF

# Run the Auditor (stub for now; will be implemented in PoC Workstream 1)
# npx hpe-ds-ai audit
```

### 4. Pick a contribution task (2 min)

- **Add a component:** See "Task 1: Add a New Grommet Component to Knowledge Base"
- **Add a skill:** See "Task 2: Add a New Remediation Skill to Engineer"
- **Fix a bug:** Check open issues in GitHub; start with "good first issue" label
- **Unsure?** Ask in #design-system-agent Slack channel

### 5. Before you commit

- [ ] Read the relevant agent's instructions.md (e.g., if adding a skill, read `prompts/engineer/instructions.md`)
- [ ] Check DATA_CONTRACTS.md if changing any agent I/O
- [ ] Test your change with a real Grommet repo (or use knowledge base examples)
- [ ] Run `npm test` (if unit tests exist; PoC has minimal test coverage)
- [ ] Commit with a clear message: `feat: add Button component to knowledge base` or `docs: clarify Strategist ranking logic`

---

## Directory Structure

```
packages/design-system-agent/
├── .copilot-instructions.md        ← You are here
├── DOCUMENTATION.md                 ← Full architecture, agent roles, continuous loop
├── ROADMAP.md                       ← 3-phase delivery strategy with Phase 1 overview
├── PoC-IMPLEMENTATION.md            ← 5 workstreams, milestones, risk mitigations
├── DATA_CONTRACTS.md                ← 8 inter-agent JSON payload contracts
├── .hpedsrc.example                 ← Sample team configuration
│
├── prompts/                          ← Agent instructions (LLM prompts)
│   ├── auditor/
│   │   ├── agent.md                 ← Role, 11-point metric framework, I/O contract
│   │   ├── instructions.md          ← Scoring logic, N/A handling, audit scopes
│   │   └── knowledge/               ← Component, pattern, token definitions (YAML/JSON)
│   │       ├── components/          ← 60+ Grommet components (Button.yaml, etc.)
│   │       ├── patterns/            ← 6 patterns (login-form, data-table, etc.)
│   │       └── tokens/              ← hpe-design-tokens (color, spacing, typography)
│   │
│   ├── orchestrator/
│   │   ├── agent.md                 ← New: Role, state machine, I/O contract
│   │   └── instructions.md          ← New: Detailed algorithms, config discovery
│   │
│   ├── strategist/
│   │   ├── agent.md                 ← New: Impact/Effort matrix, classification
│   │   └── instructions.md          ← New: Ranking algorithm, fallback logic
│   │
│   ├── engineer/
│   │   ├── instructions.md          ← Role, context mgmt, output requirements
│   │   └── skills.md                ← New: Remediation + generation skills, test matrix
│   │
│   └── reporter/
│       └── instructions.md          ← New: Telemetry payload, privacy, P1 detection
│
├── bin/
│   └── hpeds-ai.ts                  ← CLI stub (audit, gen, undo commands)
│
├── knowledge/                        ← Local knowledge base (mirrors prompts/auditor/knowledge/)
│   ├── components/
│   ├── patterns/
│   └── tokens/
│
├── package.json
└── tsconfig.json
```

---

## Key Design Decisions

### 1. PoC Scope = Segment A Only (Grommet + React)

**Why?** Grommet has the most HPEDS adoption (40% of teams); tightest feedback loop; fastest time-to-value.

- **When adding features:** Do NOT add support for Material-UI, Chakra, Vue, Angular, or custom token scenarios in PoC. Escalate to MVP/Enhancements.
- **Exception:** If a feature directly enables PoC validation (e.g., post-gen audit toggle), include it.

### 2. All Engineer Changes Require Approval Gates

**Why?** Safety: humans control code application. Telemetry: tracks acceptance rates.

- **DO:** Prompt user before Engineer applies diffs or writes generated files. Show diff previews. Support "review" mode.
- **DON'T:** Apply changes without explicit user approval or execute rollbacks silently.

### 3. Orchestrator Owns Loop Control

**Why?** Single source of truth for state, eliminates re-entrance bugs, centralizes approval logic.

- **DO:** All inter-agent communication flows through Orchestrator. Use DATA_CONTRACTS payloads.
- **DON'T:** Have agents invoke each other directly. Have Strategist directly queue Engineer tasks.

### 4. Data Contracts Over Direct I/O

**Why?** Enables independent testing, async development, clear interfaces.

- **DO:** Define JSON schemas in DATA_CONTRACTS.md before implementing agents. Test contracts separately from agents.
- **DON'T:** Change I/O formats without updating DATA_CONTRACTS.md. Assume implicit payloads between agents.

### 5. Context Budgets are Hard Constraints

**Why?** LLM context window is finite; unbounded evidence causes non-determinism.

- **DO:** Auditor output capped at ~8KB; Engineer generation at ~6KB; evidence excerpts at ~2KB; summaries at ~500 tokens. Load only declared scope.
- **DON'T:** Pass full source files to agents. Embed unlimited examples. Load all components even if scope is `/src/components/Button.tsx`.

### 6. Optional Post-Gen Audit in PoC (Default in MVP+)

**Why?** Fast iteration now; stricter QA later.

- **DO:** Honor `post_generation_audit: false` in PoC .hpedsrc. Add logic for `true` (re-audit generated code, detect regressions).
- **DON'T:** Force post-gen audit in PoC. Assume teams want speed over safety validation initially.

### 7. No Source Code in Telemetry

**Why?** Privacy-first; comply with data retention laws.

- **DO:** Emit metric scores, error counts, acceptance rates, timestamp, team segment. Redact paths.
- **DON'T:** Include file contents, code snippets, team names, user emails, git commits in telemetry payloads.

### 8. Grommet Skills Only (No Other UI Libraries)

**Why?** PoC scope; deep expertise in one library beats shallow coverage of many.

- **DO:** Add Grommet-specific AST rules, component upgrade patterns, prop mappings.
- **DON'T:** Add Material-UI Button rules, Chakra TypeScript patterns, or framework-agnostic fixes in PoC (defer to MVP).

---

## Common Contribution Tasks

### Task 1: Add a New Grommet Component to Knowledge Base

**File:** `prompts/auditor/knowledge/components/ComponentName.yaml`

**Template:**

```yaml
name: 'Grommet Component Name'
description: 'Brief description'
props:
  - name: prop_name
    type: string | boolean | ReactNode
    required: true
    description: 'What it does'
    deprecated: false
    migration: 'null'
accessibility:
  - role: button | checkbox | etc.
  - aria: ['aria-label', 'aria-expanded']
  - wcag: 'WCAG 2.1 AA'
examples:
  - label: 'Basic usage'
    code: |
      <Button primary label="Click me" />
  - label: 'With icon'
    code: |
      <Button primary icon={<Icon />} />
deprecated_props:
  - name: colorIndex
    suggested_replacement: 'Use theme tokens instead'
```

**Testing:** Add to `__tests__/components/` and verify Auditor can load it without schema errors.

---

### Task 2: Add a New Remediation Skill to Engineer

**File:** `prompts/engineer/skills.md` → Add under "Remediation Skills"

**Template:**

```markdown
### Skill Name

**Trigger:** When Auditor reports [Metric] [Finding Type]

**Input:** {...}
**Algorithm:** Step-by-step logic
**Test cases:** 3-5 specific examples
**Output:** JSON diff format (before/after, confidence, requires_review flag)

**Acceptance criteria for PoC:**

- All test cases pass
- Confidence ≥ 80%
- No false positives on 10 real codebases
```

**Testing:** Create test fixtures in `__tests__/engineer/` and run against real Grommet components.

---

### Task 3: Extend Strategist Ranking (e.g., Add New Metric)

**File:** `prompts/strategist/instructions.md` → Update "Impact calculation" and "Effort lookup table"

**Steps:**

1. Define metric's weight in DOCUMENTATION.md (already done; don't repeat)
2. Add effort estimates per finding type in lookup table
3. Add impact calculation formula for that metric
4. Test with 10 real audit results (from knowledge base examples)
5. Validate top 3 recommendations align with team expectations

**Testing:** Use real Auditor scorecards from pilot team repos (if available in PoC) to validate ranking logic.

---

### Task 4: Add a New Generation Pattern

**Files:**

- `prompts/auditor/knowledge/patterns/pattern-name.yaml`
- `prompts/auditor/knowledge/patterns/template.tsx` (canonical implementation)

**Template:**

```yaml
name: login-form
description: 'User login form with email, password, remember-me'
framework: react
ui_library: grommet
components_used: [Box, TextInput, Button, CheckBox]
tokens_used: [hpe_color_ui_background, hpe_spacing_medium]
canonical_example: template.tsx
prompts_that_trigger_this:
  - 'login form'
  - 'sign in page'
  - 'authentication form with grommet'
generation_params:
  - name: include_remember_me
    type: boolean
    default: true
  - name: include_forgot_password
    type: boolean
    default: true
acceptance_criteria:
  - Generated code is valid TypeScript React
  - Imports Grommet + grommet-theme-hpe
  - Uses hpe-design-tokens for colors/spacing
  - Storybook story included
```

**Testing:** Run `hpe-ds-ai gen --prompt "Create a login form"` and verify output matches canonical template.

---

### Task 5: Add a New Validation Rule to Orchestrator

**File:** `prompts/orchestrator/instructions.md` → Update "Config discovery & validation" or add new gate

**Steps:**

1. Define validation rule in .hpedsrc.example (if config-related)
2. Add check in `validate_config()` function
3. Provide helpful error message if validation fails
4. Test with invalid .hpedsrc files (missing fields, wrong values, etc.)

**Testing:** Create test fixtures in `__tests__/orchestrator/` with valid/invalid configs.

---

### Task 6: Update Agent Instructions (e.g., Fix Context Budget)

**File:** `prompts/{agent}/instructions.md`

**Process:**

1. Update instructions inline with code/pseudocode
2. Add context budget comment at top or in relevant section
3. Test with context measurement tools (token counters)
4. Update DATA_CONTRACTS.md if I/O changes
5. Commit with clear message (e.g., "feat: reduce Auditor context budget to 7KB")

---

## Testing & Validation

### Unit Testing

- **Agent instructions:** Validate with concrete examples (input → pseudocode execution → expected output)
- **Data contracts:** Validate JSON schemas against test payloads
- **Skills:** Test with 3+ real codebases per skill
- **Knowledge base:** Load and verify all YAML/JSON files parse correctly

### Integration Testing

- **Orchestrator + Auditor:** Run audit loop on test repo; verify scorecard emitted
- **Orchestrator + Strategist:** Feed scorecard to Strategist; verify top 3 recommendations
- **Orchestrator + Engineer:** Feed recommendations to Engineer; verify diffs generated and approved
- **End-to-end:** Run full loop `audit → strategize → engineer → report` with approval gates

### PoC Validation (with Pilot Teams)

Validation occurs in Weeks 4–6 per [PoC-IMPLEMENTATION.md](PoC-IMPLEMENTATION.md); involve 3–5 Segment A teams.

- **Auditor accuracy:** 80%+ of top 3 recommendations are actionable
- **Engineer quality:** 70%+ of diffs/generated code accepted without modification
- **No regressions:** Post-remediation scores don't drop >5 points
- **Feedback:** Teams report "clear next steps" and "understandable diffs"

---

## Context Management Checklist

When adding features to agents, ensure:

- [ ] **Scope-first:** Load only the declared scope (e.g., `/src/components`, not entire repo)
- [ ] **Evidence tiers:** Prefer citations over full files; excerpt large findings
- [ ] **Context budgets:** (Use OpenAI tokenizer; 1 token ≈ 4 bytes)
  - Auditor: ~8KB (~3,200 tokens) input + 8KB output
  - Engineer remediation: ~8KB input + 2KB diffs output
  - Engineer generation: ~6KB input + 2KB generated code output
  - Strategist: ~1KB input + 500B output
  - Reporter: ~2KB input, ~1KB output
- [ ] **No unbounded lookups:** Don't load all 60+ components if only checking 2 files
- [ ] **Caching strategy:** PoC has no caching (OK); MVP will cache audits per repo
- [ ] **Token counters:** Use OpenAI token counter or similar to validate budget compliance

---

## Privacy & Telemetry Checklist

When working on Reporter or approval flows:

- [ ] **No source code in telemetry:** Never emit file contents, code snippets, or full errors
- [ ] **Minimal PII:** No team names, user emails, repo paths (use hashes if needed)
- [ ] **Opt-out honored:** If `telemetry_opt_in: false`, emit nothing
- [ ] **Retention policy:** Data deleted after 12 months (configurable)
- [ ] **P1 threshold:** System gaps require 2+ teams reporting before auto-ticket (MVP feature)
- [ ] **Privacy review:** Contract changes require review before merging

---

## Approval Gate Checklist

When implementing approval flows (Orchestrator, user prompts):

- [ ] **Before Engineer applies diffs:** Show summary + preview; options: yes/no/review/undo
- [ ] **Before Engineer writes generated files:** Show file count + snippets; options: yes/no/review
- [ ] **Before Reporter emits telemetry:** Honor opt-out flag (no prompt needed if opt-in=true config)
- [ ] **Before rollback:** If post-gen audit detects regression, prompt user before restoring checkpoint
- [ ] **Error recovery:** If Engineer fails, log error AND offer rollback; don't fail silently

---

## Debugging Tips

### "Auditor scored too low"

- Check component knowledge base: does Button.yaml include all current Grommet props?
- Check metric definitions in DOCUMENTATION.md: is scoring formula correct?
- Run with `--debug` to see which components/findings triggered each metric

### "Strategist picked wrong top 3"

- Verify Auditor findings are accurate (re-run audit with `--debug`)
- Check impact calculation: are metric weights applied correctly?
- Check effort estimates: are effort_map entries reasonable for your finding types?
- Test ranking algorithm directly on a scorecard (pseudocode in strategist/instructions.md)

### "Engineer generated invalid code"

- Verify template.tsx is valid TypeScript React (run TypeScript compiler)
- Check imports: are all used components imported from grommet?
- Check tokens: are all colors/spacing from hpe-design-tokens?
- Test generation on a simple prompt first ("Create a button") before complex ones

### "Orchestrator not finding .hpedsrc"

- Verify .hpedsrc exists in one of three locations: repo root, workspace root, home dir
- Check .hpedsrc format: valid YAML/JSON? Required fields present (framework, team_segment, scope)?
- Run `hpe-ds-ai --validate` to validate config without invoking agents

### "Checkpoint restore failed"

- Verify .hpeds-undo-checkpoint directory exists and is not corrupt
- Check checkpoint age: if >7 days old, checkpoint may have been auto-deleted
- Inspect metadata.json: does it list all files that were modified?

---

## References & Further Reading

| Document                                                                     | Purpose                                                                 |
| ---------------------------------------------------------------------------- | ----------------------------------------------------------------------- |
| [DOCUMENTATION.md](DOCUMENTATION.md)                                         | Full architecture, 11-point metrics, continuous loop, data flow         |
| [ROADMAP.md](ROADMAP.md)                                                     | 3-phase delivery (PoC/MVP/Enhancements), team segments, success metrics |
| [PoC-IMPLEMENTATION.md](PoC-IMPLEMENTATION.md)                               | 5 workstreams, milestones, dependencies, risk mitigations (4-6 weeks)   |
| [DATA_CONTRACTS.md](DATA_CONTRACTS.md)                                       | 8 inter-agent JSON schemas, approval payloads, checkpoint format        |
| [.hpedsrc.example](.hpedsrc.example)                                         | Team configuration template with examples                               |
| [prompts/auditor/instructions.md](prompts/auditor/instructions.md)           | 11-point scoring logic, N/A handling, metric definitions                |
| [prompts/engineer/skills.md](prompts/engineer/skills.md)                     | Remediation + generation skills, test matrix, PoC constraints           |
| [prompts/strategist/agent.md](prompts/strategist/agent.md)                   | Impact/Effort matrix, Consumer vs. System classification                |
| [prompts/orchestrator/instructions.md](prompts/orchestrator/instructions.md) | State machine, config discovery, approval gating                        |

---

## Questions?

- **Architecture questions:** See DOCUMENTATION.md and ROADMAP.md
- **PoC scope questions:** See PoC-IMPLEMENTATION.md and .hpedsrc.example
- **Agent behavior questions:** See respective agent instructions.md
- **Data flow questions:** See DATA_CONTRACTS.md
- **Contribution guidance:** See "Common Contribution Tasks" above

---

## Code Style & Conventions

- **Agent instructions:** Type pseudocode in `def function_name():` blocks; include JSON examples
- **Payloads:** Use camelCase for JSON keys (matches Auditor output convention)
- **Comments:** Explain "why" not "what"; reference metrics or design decisions (e.g., "Per Decision #3: Orchestrator owns loop control...")
- **Metric weights:** Never hardcode metric weights; always reference DOCUMENTATION.md (11-point framework section)
- **No custom tokens:** Escalate findings about custom/non-standard tokens to System Enablement (don't try to auto-fix in PoC)
- **Test naming:** `test_<feature>_<scenario>` (e.g., `test_token_compliance_hardcoded_color`)
- **Commits:** Use conventional commits: `feat:`, `fix:`, `docs:`, `test:`, `refactor:`

---

Last updated: March 1, 2026
